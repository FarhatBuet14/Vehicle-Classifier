epochs = 100
batch_size = 32
verbose = 1

####################### Defining the model ##############################

model = Sequential()
model.add(Convolution2D(32, 3, 3 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
model.add(Convolution2D(32, 3, 3 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.2))


model.add(Convolution2D(64, 2, 2 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
model.add(Convolution2D(32, 2, 2 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.2))


model.add(Convolution2D(128, 2, 2 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
model.add(Convolution2D(128, 2, 2 , 
                        input_shape=(imageSize,imageSize,3),activation= 'relu' ))
#model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.2))


model.add(Flatten())
model.add(Dense(128, activation= 'relu' ))
model.add(Dense(num_classes, activation= 'softmax' ))

#################### Summary of the Model ###############################

model.summary()

#################### Compiling the Model ################################
optimizer = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)
model.compile(loss= 'categorical_crossentropy' , 
              optimizer= optimizer , metrics=[ 'accuracy' ])

#################### Defining the Checkpoints ###########################
l_r = ReduceLROnPlateau(monitor='val_acc', factor=0.5, 
                                  patience=3, verbose=1, 
                                  min_lr=0.000001)

wigth  = ModelCheckpoint(weightFile, monitor = 'val_categorical_accuracy' )
callbacks = [wigth, l_r]



datagen = ImageDataGenerator(featurewise_center=True,
                            rotation_range=20,
                            width_shift_range=0.2,
                            height_shift_range=0.2,
                            horizontal_flip=True)

datagen.fit(X_train)

model.fit_generator(datagen.flow(X_train, y_train, batch_size = 32),
                    validation_data = datagen.flow(X_val, y_val, batch_size = 32),
                    steps_per_epoch = len(X_train) / 32, 
                    validation_steps = len(X_val) / 16, epochs = epochs, 
                    callbacks = callbacks, verbose = verbose)














Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 124, 124, 32)      9248      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 61, 61, 64)        8256      
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 60, 60, 32)        8224      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 29, 29, 128)       16512     
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 28, 28, 128)       65664     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 25088)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               3211392   
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 387       
=================================================================
Total params: 3,320,579
Trainable params: 3,320,579
Non-trainable params: 0
____________________________









_____________________________________
Epoch 1/100
430/429 [==============================] - 55s 127ms/step - loss: 0.8726 - acc: 0.6014 - val_loss: 0.7958 - val_acc: 0.6381
Epoch 2/100
430/429 [==============================] - 51s 119ms/step - loss: 0.7642 - acc: 0.6549 - val_loss: 0.7326 - val_acc: 0.6672
Epoch 3/100
430/429 [==============================] - 51s 118ms/step - loss: 0.7121 - acc: 0.6824 - val_loss: 0.6901 - val_acc: 0.6921
Epoch 4/100
430/429 [==============================] - 51s 119ms/step - loss: 0.6784 - acc: 0.6975 - val_loss: 0.6606 - val_acc: 0.7156
Epoch 5/100
430/429 [==============================] - 51s 118ms/step - loss: 0.6492 - acc: 0.7134 - val_loss: 0.6920 - val_acc: 0.6846ETA: 15s - loss: 0.6523 - acc: 0.7116
Epoch 6/100
430/429 [==============================] - 50s 116ms/step - loss: 0.6315 - acc: 0.7214 - val_loss: 0.6095 - val_acc: 0.7392
Epoch 7/100
430/429 [==============================] - 50s 116ms/step - loss: 0.6073 - acc: 0.7310 - val_loss: 0.6205 - val_acc: 0.7356
Epoch 8/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5957 - acc: 0.7416 - val_loss: 0.6269 - val_acc: 0.7330
Epoch 9/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5743 - acc: 0.7512 - val_loss: 0.5739 - val_acc: 0.7608
Epoch 10/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5630 - acc: 0.7583 - val_loss: 0.5570 - val_acc: 0.7700
Epoch 11/100
430/429 [==============================] - 48s 111ms/step - loss: 0.5543 - acc: 0.7631 - val_loss: 0.5365 - val_acc: 0.7719
Epoch 12/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5445 - acc: 0.7696 - val_loss: 0.5870 - val_acc: 0.7435
Epoch 13/100
430/429 [==============================] - 48s 111ms/step - loss: 0.5256 - acc: 0.7759 - val_loss: 0.6293 - val_acc: 0.7075
Epoch 14/100
430/429 [==============================] - 48s 111ms/step - loss: 0.5176 - acc: 0.7812 - val_loss: 0.5247 - val_acc: 0.7781
Epoch 15/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5097 - acc: 0.7874 - val_loss: 0.5472 - val_acc: 0.7624
Epoch 16/100
430/429 [==============================] - 48s 112ms/step - loss: 0.5076 - acc: 0.7878 - val_loss: 0.5035 - val_acc: 0.7883
Epoch 17/100
430/429 [==============================] - 48s 111ms/step - loss: 0.4928 - acc: 0.7967 - val_loss: 0.5129 - val_acc: 0.7850
Epoch 18/100
430/429 [==============================] - 48s 112ms/step - loss: 0.4851 - acc: 0.7988 - val_loss: 0.5234 - val_acc: 0.7899
Epoch 19/100
430/429 [==============================] - 48s 111ms/step - loss: 0.4806 - acc: 0.8029 - val_loss: 0.5895 - val_acc: 0.7471
Epoch 20/100
430/429 [==============================] - 48s 112ms/step - loss: 0.4676 - acc: 0.8078 - val_loss: 0.5485 - val_acc: 0.7539
Epoch 21/100
430/429 [==============================] - 48s 111ms/step - loss: 0.4686 - acc: 0.8032 - val_loss: 0.4683 - val_acc: 0.8086ETA: 24s - loss: 0.4687 - acc: 0.8054
Epoch 22/100
430/429 [==============================] - 48s 112ms/step - loss: 0.4626 - acc: 0.8096 - val_loss: 0.5143 - val_acc: 0.7873
Epoch 23/100
430/429 [==============================] - 48s 112ms/step - loss: 0.4525 - acc: 0.8144 - val_loss: 0.4891 - val_acc: 0.7984
Epoch 24/100
430/429 [==============================] - 48s 111ms/step - loss: 0.4572 - acc: 0.8092 - val_loss: 0.4898 - val_acc: 0.7929

Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
Epoch 25/100
430/429 [==============================] - 48s 112ms/step - loss: 0.4235 - acc: 0.8272 - val_loss: 0.4789 - val_acc: 0.8004
Epoch 26/100
430/429 [==============================] - 53s 124ms/step - loss: 0.4192 - acc: 0.8306 - val_loss: 0.4463 - val_acc: 0.8177
Epoch 27/100
430/429 [==============================] - 52s 121ms/step - loss: 0.4128 - acc: 0.8336 - val_loss: 0.4509 - val_acc: 0.8066
Epoch 28/100
430/429 [==============================] - 54s 125ms/step - loss: 0.4095 - acc: 0.8370 - val_loss: 0.4460 - val_acc: 0.8154
Epoch 29/100
430/429 [==============================] - 53s 124ms/step - loss: 0.4095 - acc: 0.8368 - val_loss: 0.4229 - val_acc: 0.8213
Epoch 30/100
430/429 [==============================] - 50s 117ms/step - loss: 0.4039 - acc: 0.8377 - val_loss: 0.4380 - val_acc: 0.8210
Epoch 31/100
430/429 [==============================] - 49s 114ms/step - loss: 0.4020 - acc: 0.8359 - val_loss: 0.4302 - val_acc: 0.8262
Epoch 32/100
430/429 [==============================] - 49s 114ms/step - loss: 0.4038 - acc: 0.8354 - val_loss: 0.4437 - val_acc: 0.8194
Epoch 33/100
430/429 [==============================] - 49s 113ms/step - loss: 0.3930 - acc: 0.8407 - val_loss: 0.4227 - val_acc: 0.8266
Epoch 34/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3967 - acc: 0.8395 - val_loss: 0.4536 - val_acc: 0.8050
Epoch 35/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3909 - acc: 0.8446 - val_loss: 0.4372 - val_acc: 0.8158
Epoch 36/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3924 - acc: 0.8446 - val_loss: 0.4309 - val_acc: 0.8236

Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
Epoch 37/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3772 - acc: 0.8506 - val_loss: 0.4112 - val_acc: 0.8367
Epoch 38/100
430/429 [==============================] - 52s 120ms/step - loss: 0.3745 - acc: 0.8498 - val_loss: 0.4061 - val_acc: 0.8344
Epoch 39/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3729 - acc: 0.8498 - val_loss: 0.4070 - val_acc: 0.8380
Epoch 40/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3724 - acc: 0.8504 - val_loss: 0.4088 - val_acc: 0.8321
Epoch 41/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3712 - acc: 0.8512 - val_loss: 0.4056 - val_acc: 0.8292
Epoch 42/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3665 - acc: 0.8533 - val_loss: 0.4070 - val_acc: 0.8354

Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.
Epoch 43/100
430/429 [==============================] - 50s 116ms/step - loss: 0.3615 - acc: 0.8542 - val_loss: 0.4021 - val_acc: 0.8413
Epoch 44/100
430/429 [==============================] - 54s 125ms/step - loss: 0.3628 - acc: 0.8571 - val_loss: 0.4027 - val_acc: 0.8334
Epoch 45/100
430/429 [==============================] - 53s 123ms/step - loss: 0.3574 - acc: 0.8564 - val_loss: 0.4153 - val_acc: 0.8384
Epoch 46/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3613 - acc: 0.8568 - val_loss: 0.3939 - val_acc: 0.8397

Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.
Epoch 47/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3573 - acc: 0.8559 - val_loss: 0.3913 - val_acc: 0.8403
Epoch 48/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3547 - acc: 0.8609 - val_loss: 0.3959 - val_acc: 0.8416
Epoch 49/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3518 - acc: 0.8607 - val_loss: 0.4092 - val_acc: 0.8292
Epoch 50/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3488 - acc: 0.8601 - val_loss: 0.4073 - val_acc: 0.8341
Epoch 51/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3545 - acc: 0.8597 - val_loss: 0.4069 - val_acc: 0.8344

Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.
Epoch 52/100
430/429 [==============================] - 48s 113ms/step - loss: 0.3494 - acc: 0.8591 - val_loss: 0.3895 - val_acc: 0.8449
Epoch 53/100
430/429 [==============================] - 48s 113ms/step - loss: 0.3498 - acc: 0.8603 - val_loss: 0.4051 - val_acc: 0.8348
Epoch 54/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3481 - acc: 0.8603 - val_loss: 0.4048 - val_acc: 0.8341
Epoch 55/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3500 - acc: 0.8598 - val_loss: 0.4006 - val_acc: 0.8406

Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.
Epoch 56/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3493 - acc: 0.8594 - val_loss: 0.3921 - val_acc: 0.8459
Epoch 57/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3519 - acc: 0.8589 - val_loss: 0.4016 - val_acc: 0.8354
Epoch 58/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3470 - acc: 0.8605 - val_loss: 0.3978 - val_acc: 0.8420
Epoch 59/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3461 - acc: 0.8607 - val_loss: 0.4024 - val_acc: 0.8384

Epoch 00059: ReduceLROnPlateau reducing learning rate to 1e-06.
Epoch 60/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3421 - acc: 0.8619 - val_loss: 0.3987 - val_acc: 0.8413
Epoch 61/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3502 - acc: 0.8584 - val_loss: 0.4035 - val_acc: 0.8433
Epoch 62/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3488 - acc: 0.8598 - val_loss: 0.3995 - val_acc: 0.8338
Epoch 63/100
430/429 [==============================] - 48s 113ms/step - loss: 0.3430 - acc: 0.8628 - val_loss: 0.3913 - val_acc: 0.8406
Epoch 64/100
430/429 [==============================] - 55s 127ms/step - loss: 0.3464 - acc: 0.8638 - val_loss: 0.4002 - val_acc: 0.8364
Epoch 65/100
430/429 [==============================] - 51s 120ms/step - loss: 0.3460 - acc: 0.8610 - val_loss: 0.3988 - val_acc: 0.8423
Epoch 66/100
430/429 [==============================] - 49s 115ms/step - loss: 0.3469 - acc: 0.8626 - val_loss: 0.3888 - val_acc: 0.8439
Epoch 67/100
430/429 [==============================] - 49s 113ms/step - loss: 0.3471 - acc: 0.8629 - val_loss: 0.3904 - val_acc: 0.8410
Epoch 68/100
430/429 [==============================] - 49s 114ms/step - loss: 0.3455 - acc: 0.8601 - val_loss: 0.3918 - val_acc: 0.8390
Epoch 69/100
430/429 [==============================] - 49s 113ms/step - loss: 0.3452 - acc: 0.8581 - val_loss: 0.3942 - val_acc: 0.8423
Epoch 70/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3465 - acc: 0.8593 - val_loss: 0.3990 - val_acc: 0.8439
Epoch 71/100
430/429 [==============================] - 49s 113ms/step - loss: 0.3466 - acc: 0.8634 - val_loss: 0.3953 - val_acc: 0.8367
Epoch 72/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3520 - acc: 0.8616 - val_loss: 0.3841 - val_acc: 0.8374
Epoch 73/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3471 - acc: 0.8631 - val_loss: 0.3960 - val_acc: 0.8410
Epoch 74/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3455 - acc: 0.8606 - val_loss: 0.4035 - val_acc: 0.8400
Epoch 75/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3422 - acc: 0.8616 - val_loss: 0.3985 - val_acc: 0.8341
Epoch 76/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3515 - acc: 0.8574 - val_loss: 0.3848 - val_acc: 0.8547
Epoch 77/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3473 - acc: 0.8589 - val_loss: 0.4010 - val_acc: 0.8410
Epoch 78/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3492 - acc: 0.8615 - val_loss: 0.3953 - val_acc: 0.8367
Epoch 79/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3479 - acc: 0.8617 - val_loss: 0.3929 - val_acc: 0.8348
Epoch 80/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3449 - acc: 0.8647 - val_loss: 0.3815 - val_acc: 0.8488
Epoch 81/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3475 - acc: 0.8608 - val_loss: 0.4017 - val_acc: 0.8354
Epoch 82/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3454 - acc: 0.8624 - val_loss: 0.3885 - val_acc: 0.8498
Epoch 83/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3453 - acc: 0.8610 - val_loss: 0.3907 - val_acc: 0.8426
Epoch 84/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3488 - acc: 0.8602 - val_loss: 0.3942 - val_acc: 0.8449
Epoch 85/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3428 - acc: 0.8639 - val_loss: 0.3832 - val_acc: 0.8426
Epoch 86/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3461 - acc: 0.8611 - val_loss: 0.3960 - val_acc: 0.8413
Epoch 87/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3395 - acc: 0.8642 - val_loss: 0.3983 - val_acc: 0.8498
Epoch 88/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3503 - acc: 0.8628 - val_loss: 0.3885 - val_acc: 0.8482
Epoch 89/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3464 - acc: 0.8574 - val_loss: 0.3954 - val_acc: 0.8367
Epoch 90/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3453 - acc: 0.8636 - val_loss: 0.4000 - val_acc: 0.8361
Epoch 91/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3408 - acc: 0.8632 - val_loss: 0.3898 - val_acc: 0.8436
Epoch 92/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3435 - acc: 0.8643 - val_loss: 0.3860 - val_acc: 0.8475
Epoch 93/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3450 - acc: 0.8630 - val_loss: 0.3942 - val_acc: 0.8374
Epoch 94/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3414 - acc: 0.8661 - val_loss: 0.3905 - val_acc: 0.8436
Epoch 95/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3435 - acc: 0.8638 - val_loss: 0.3840 - val_acc: 0.8501
Epoch 96/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3449 - acc: 0.8601 - val_loss: 0.3879 - val_acc: 0.8413
Epoch 97/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3400 - acc: 0.8644 - val_loss: 0.3939 - val_acc: 0.8426
Epoch 98/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3447 - acc: 0.8633 - val_loss: 0.3939 - val_acc: 0.8433
Epoch 99/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3456 - acc: 0.8612 - val_loss: 0.3937 - val_acc: 0.8416
Epoch 100/100
430/429 [==============================] - 48s 112ms/step - loss: 0.3454 - acc: 0.8609 - val_loss: 0.3876 - val_acc: 0.8462



